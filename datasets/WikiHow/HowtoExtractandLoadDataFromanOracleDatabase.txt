@summary
export the schemas using the exp utility on the rows=n parameter.

@summary
export the data from the small code tables either using fastreader or native exp utility.

@summary
set up the destination database with all the same global roles, users, user privileges, system triggers (on_logon) and tablespaces (i.e.

@summary
import the schemas using imp (schemas and small tables).

@summary
create global object privileges and object synonyms as they were on the original instance.

@summary
load the data from tables which were extracted using fastreader into the target (destination) database.

@summary
recreate indexes (if removed) on the large loaded tables, this is a major, computationally intensive step, comparable to the unload/load phase, care should be invested in improving the performance of this step by increasing the sort area or pga memory sizes, performing several builds simultaneously under the available constraints (for instance you cannot effectively build two indexes on the same table at the same time), possible creating partitioned indexes in an unusable state and the rebuilding several partitions simultaneously, etc.

@summary
,

@summary
enable constraints and triggers on the large tables with the invalidate clause for a performance improvement.

@summary
,

@summary
recreate and/or rebuild materialized views using “complete refresh”.

@summary
recreate (if not already present) indexes on the materialized views.

@article
 During this stage all the objects which are non data, such as PL/SQL, Sequences, Views, Table definitions, Object privileges etc. will be exported. There will be one such exp file per each schema exported. FastReader allows exporting of the schema definitions such as tables, constraints, sequences, triggers and generating scripts. The data from the large tables (fact tables and the large dimensions) should be exported using FastReader.;
, Native exp should be used with the TABLES parameter specifying only the small tables to be extracted. There will be one exp file per each schema exported.
 all the settings which are not exported using exp). If there is a need for a different tablespace/storage configuration then this should be taken into account in the latter stages.
 FastReader allows exporting of the schema definitions such as tables, constraints, sequences, triggers, etc. to be created on destination database

, These definitions are not exported during the schema export by exp.
 FastReader is utilizing the existing high-speed loaders for each supported database vendor (for instance, when data to be loaded into Oracle, then sqlldr will be utilized). FastReader creates automatically the control files for every supported target database vendor that reflect what tables/columns/data to be loaded and the scripts for actually executing the load. Before the load all the constraints and triggers on the large tables which can prevent “direct load” mode or hurt load performance should be disabled. Constraints on target database can be disabled / enabled also from FastReader GUI (Configurator). If materialized views are used with “refresh on commit” option, these should be disabled and refreshed completely at a later phase. For better control of the process the indexes maybe be dropped and recreated after the load. If the indexes remain then during the direct load, Oracle will build them using an efficient method similar in performance to creating an index on a full table. It is possible to load several tables and/or partitions simultaneously, by running several SQL loaders at once. This can improve load performance significantly on a multi-processor machine with good I/O.
,, It is also possible that materialized views can be moved with their data intact and then their status changed to TRUSTED or created as if from pre-built tables but this step is more complex in terms of correct execution and setup

,